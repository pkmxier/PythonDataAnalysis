{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>Факультет \"Прикладная математика\" МАИ</h1>\n",
    "<h2>Курс \"Основы Python для анализа данных\"</h2>\n",
    "<h2>Артамонов Игорь Михайлович</h2>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Занятие № 12. Искусственные нейронные сети.</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общение / вопросы по курсу\n",
    "\n",
    "Платформа для групповой работы Atlassian Confluence факультета \"Прикладная математика\"\n",
    "\n",
    "https://mai.moscow/display/PYTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### О чем говорим\n",
    "* Линейная разделимость\n",
    "* Перцептрон\n",
    "* Метод опорных векторов\n",
    "* Ядерные методы\n",
    "* \n",
    "* Детектирование лиц\n",
    "* Распозавание лиц\n",
    "* Сегментация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sc\n",
    "from numpy.random import randn\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib.patches import Ellipse\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Постановка задачи. Линейная разделимость.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть у нас есть два множества $X_0 \\subset \\mathbb{R}^{n}$ и $X_1 \\subset \\mathbb{R}^{n}$. <br>Они называются <i>линейно разделимыми</i>, если $\\exists W \\in \\mathbb{R}^{n}, \\epsilon > 0 $, такое что $\\forall x_0, x_1: x_0 \\in X_0, x_1 \\in X_1,  |Wx_0 - Wx_1| > \\epsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/No0tXOKWTx39iV2CJLjCGaFGr1520492096_kc\">\n",
    "<a href=\"https://static.commonlounge.com/fp/original/No0tXOKWTx39iV2CJLjCGaFGr1520492096_kc\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача классификации:\n",
    "\n",
    "1. Задано конечное множество $X \\subset \\mathbb{R}^{n}$<br>\n",
    "2. Каждому вектору $x_i \\in X$ сопоставлено значение $y \\in Y=\\{-1,1\\}$\n",
    "\n",
    "Алгоритм должен построить функцию $F(x) = y$ с аргументом $x \\in \\mathbb{R}^{n}$, результатот которой является метка $y \\in Y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Перцептрон (Rosenblatt, 1959)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"images/Illustration-of-the-decision-boundary-of-a-perceptron-model-for-twodimensional-inputs.png\">\n",
    "<a href=\"https://www.researchgate.net/publication/315835528/figure/fig1/AS:481450245005312@1491798091106/Illustration-of-the-decision-boundary-of-a-perceptron-model-for-twodimensional-inputs.png\">\n",
    "https://www.researchgate.net/publication/315835528/figure/fig1/AS:481450245005312@1491798091106/Illustration-of-the-decision-boundary-of-a-perceptron-model-for-twodimensional-inputs.png</a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "input: traning data D = (X, y)\n",
    "\n",
    "output: weigts w\n",
    "\n",
    "w = 0\n",
    "\n",
    "while not converged\n",
    "\n",
    "   for (x, y ) in D :\n",
    "   \n",
    "       if y ( w . x ) <=0\n",
    "        \n",
    "           w = w + y x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Перцептрон - многоклассовоя классификации</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Создаем $n$ классификаторов \"one vs all\"\n",
    "* Для выделения _одного_ класса используем $n$ классификаторов $F_1(x), .., F_n(x)$\n",
    "* $class = argmax(F_1(x), .., F_n(x))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multiclass-svm3-e1601952776445.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"images/intro2_perceptron.gif\">\n",
    "<a href=\"https://pmirla.github.io/2016/08/04/what-is-perceptron.html\">Perceptron Learning Algorithm in plain words</a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для дополнительного понимания - геометрическая интерпретация: <br><br>\n",
    "<a href=\"http://classes.engr.oregonstate.edu/eecs/spring2018/cs519-400/slides/week2-perceptron.pdf\">Week 2: Linear Classification: Perceptron</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Достоинства:\n",
    "    \n",
    "    * обновляются только неверно классифицированные примеры\n",
    "    * линейный\n",
    "    * возможность работы с очень большими наборами данных\n",
    "    * возможность реализации \"по поступлению данных\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример на Iris Dataset (<a href=\"https://chrisalbon.com/machine_learning/basics/perceptron_in_scikit-learn/\">Perceptron In Scikit</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Load the iris dataset\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Create our X and y data\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# View the first five observations of our y data\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# View the first five observations of our x data.\n",
    "# Notice that there are four independent variables (features)\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into 70% training data and 30% test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Train the scaler, which standarizes all the features to have mean=0 and unit variance\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "\n",
    "# Apply the scaler to the X training data\n",
    "X_train_std = sc.transform(X_train)\n",
    "\n",
    "# Apply the SAME scaler to the X test data\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a perceptron object with the parameters: 40 iterations (epochs) over the data, and a learning rate of 0.1\n",
    "ppn = Perceptron(eta0=0.1, random_state=0)\n",
    "\n",
    "# Train the perceptron\n",
    "ppn.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Apply the trained perceptron on the X data to make predicts for the y test data\n",
    "y_pred = ppn.predict(X_test_std)\n",
    "\n",
    "# View the accuracy of the model, which is: 1 - (observations predicted wrong / total observations)\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Зазор и его максимизация. Метод опорных векторов.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* перцептрон создает границу\n",
    "* как найти \"наилучшую\" границу?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/1*RWhsAxYTbneAsqqZuh373Q.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"images/svm.png\" height=600>\n",
    "\n",
    "<a href=\"https://staesthetic.files.wordpress.com/2014/02/svm.png\">https://staesthetic.files.wordpress.com/2014/02/svm.png</a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм будет корректно классифицировать объекты в том случае, если:\n",
    "\n",
    "$y_i(w^T x_i - b) \\ge 1 $\n",
    "\n",
    "Введем фукцию потерь (Hinge loss):\n",
    "\n",
    "* \"жесткая\" граница (_hard-margin SVM_)\n",
    "\n",
    "$L_h = max(0, 1-y_i(w^T x_i - b)) $\n",
    "\n",
    "* мягкая граница (_soft-margin SVM_)\n",
    "\n",
    "Если ввести в минимизируемый функционал штраф за суммарную ошибку:\n",
    "\n",
    "$\\frac{1}{2} (w^T w) + \\lambda \\sum_i \\zeta_{i} \\rightarrow min$\n",
    "\n",
    "То получим:\n",
    "\n",
    "$L_h = max(0, 1-y_i(w^T x_i - b)) + \\frac{\\lambda}{2} (w^T w)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"images/Ifeze.png\"> \n",
    "<a href=\"https://www.kaggle.com/waltermaffy/fruit-classification-pca-svm-knn-decision-tree\">Fruit Classification: PCA, SVM, KNN, Decision Tree</a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Детально: <a href=\"https://habr.com/ru/company/ods/blog/484148/\">SVM. Объяснение с нуля и реализация на python. </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">SVM с ядрами</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x \\in \\mathbb{R}^{3}, y \\in \\mathbb{R}^{3}$\n",
    "\n",
    "${\\phi (x)}^T \\phi (y) = \\sum_{i,j=1}^3 x_i x_j y_i y_j$\n",
    "\n",
    "Вычислительная сложность $ ~ O(9) $\n",
    "\n",
    "$k(x,y) = (x^T y)^2 = (x_1 y_1 + x_2 y_2 + x_3 y_3) ^2 = \\sum_{i,j=1}^3 x_i x_j y_i y_j$\n",
    "\n",
    "Вычислительная сложность $ ~ O(3) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"images/1*JVZ4FXVRlr1oN-4ffq_kNQ.png\">\n",
    "<a href=\"https://miro.medium.com/max/700/\">https://miro.medium.com/max/700/</a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Нейронные сети</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/2.webp\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Функции активации</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/ActivationFunctions.png\">\n",
    "<a href=\"https://3.bp.blogspot.com/-C9zZb522B6U/XHUf3eUr5UI/AAAAAAAAJj4/7Gn2ht4cJ5cOa7pAbTC_wiM8GZaBpoI4gCLcBGAs/w1200-h630-p-k-no-nu/ActivationFunctions.png\">https://3.bp.blogspot.com/-C9zZb522B6U/XHUf3eUr5UI/AAAAAAAAJj4/7Gn2ht4cJ5cOa7pAbTC_wiM8GZaBpoI4gCLcBGAs/w1200-h630-p-k-no-nu/ActivationFunctions.png</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Обратное распространение (backpropagation)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определения\n",
    "\n",
    "$a^{(0)} = X$\n",
    "\n",
    "$z^{(l)}_j  = W^{(l)}_j a^{(l-1)} + b^{(l)}_j $\n",
    "\n",
    "$a^{(l)}_{j} = h(z^{(l)}_j)$\n",
    "\n",
    "Обозначим \"ошибка\" $j$ -го узла на слое $l$  как\n",
    "\n",
    "$\\delta^{(l)}_{j}$ \n",
    "\n",
    "Тогда для каждого слоя:\n",
    "\n",
    "$\n",
    "\\delta^{(l)}_{j} = a^{(l)}_{j}-y_j\n",
    "$\n",
    "\n",
    "$\n",
    "\\delta^{(l-1)} = (W^{l-1})^T \\delta^{(l)} .*  h'(z^{(l-1)})\n",
    "$\n",
    "\n",
    "$\n",
    "\\delta^{(l-2)} = (W^{l-2})^T \\delta^{(l-1)} .*  h'(z^{(l-2)})\n",
    "$\n",
    "\n",
    "$...$\n",
    "\n",
    "Для $\\sigma$-функции: \n",
    "$\n",
    "h'(z^{(l-1)}) = a^{(l-1)} .* (1 - a^{(l-1)})\n",
    "$\n",
    "\n",
    "$\n",
    "h'(z^{(l-2)}) = a^{(l-2)} .* (1 - a^{(l-2)})\n",
    "$\n",
    "\n",
    "$...$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/iHDtO.png\">\n",
    "<img src=\"images/n0swE.png\">\n",
    "<a href=\"https://stackoverflow.com/questions/40575841/numpy-calculate-the-derivative-of-the-softmax-function\">https://stackoverflow.com/questions/40575841/numpy-calculate-the-derivative-of-the-softmax-function</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Пример</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/1_fnU_3MGmFp0LBIzRPx42-w.png\">\n",
    "<a href=\"https://github.com/Prakashvanapalli/TensorFlow/blob/master/Blogposts/Backpropogation_with_Images.ipynb\">https://github.com/Prakashvanapalli/TensorFlow/blob/master/Blogposts/Backpropogation_with_Images.ipynb</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "X = np.array([0.1, 0.2, 0.7])\n",
    "Y = np.array([1.0, 0.0, 0.0])\n",
    "W = np.array([[[0.1, 0.2, 0.3],\n",
    "             [0.3, 0.2, 0.7],\n",
    "             [0.1, 0.2, 0.3]],\n",
    "            [[0.2, 0.3, 0.5],\n",
    "             [0.3, 0.5, 0.7],\n",
    "             [0.6, 0.4, 0.8]],\n",
    "            [[0.1, 0.4, 0.8],\n",
    "             [0.3, 0.7, 0.2],\n",
    "             [0.5, 0.2, 0.9]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def RELU(X):\n",
    "    return X * (X > 0)\n",
    "\n",
    "def dRELU(X):\n",
    "    return 1. * (X > 0)\n",
    "\n",
    "def Sigmoid(X):\n",
    "    return 1/(1 + np.exp(-X))\n",
    "\n",
    "def dSigmoid(X):\n",
    "    S = Sigmoid(X)\n",
    "    return S/(1-S)\n",
    "\n",
    "def Softmax(X):\n",
    "    e_x = np.exp(X - np.max(X))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "def dSoftmax(softmax):\n",
    "    s = softmax.reshape(-1,1)\n",
    "    return np.diagflat(s) - np.dot(s, s.T)\n",
    "\n",
    "def CrossEntropy(y_pred, y, epsilon=1e-12):\n",
    "    y_pred = np.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    N = y_pred.shape[0]\n",
    "    return -np.sum(y*np.log(y_pred+1e-9))/N\n",
    "\n",
    "def dCrossEntropy(y_pred,y, epsilon=1e-12):\n",
    "    y_pred = np.clip(y_pred, epsilon, None)\n",
    "    return np.where(y==1,-1/y_pred, 1 / (1 - y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Прямой проход"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Z1 = W[0] @ X\n",
    "Z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "H1 = RELU(Z1)\n",
    "H1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "Z2 = W[1] @ H1\n",
    "Z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "H2 = Sigmoid(Z2)\n",
    "H2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "Z3 = W[2] @ H2\n",
    "Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "H3 = Softmax(Z3)\n",
    "Ypred = H3\n",
    "Ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "Loss = CrossEntropy(Ypred,Y)\n",
    "Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обратный проход"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss = 0.38, Ypred = [0.32128357 0.29691553 0.3818009 ]\n",
      "Epoch 1: loss = 0.35, Ypred = [0.3533074  0.28507328 0.36161932]\n",
      "Epoch 2: loss = 0.31, Ypred = [0.38882018 0.27167615 0.33950367]\n",
      "Epoch 3: loss = 0.28, Ypred = [0.42712868 0.25695545 0.31591587]\n",
      "Epoch 4: loss = 0.25, Ypred = [0.46740855 0.24118766 0.2914038 ]\n",
      "Epoch 5: loss = 0.23, Ypred = [0.50914711 0.22447816 0.26637474]\n",
      "Epoch 6: loss = 0.2, Ypred = [0.55316626 0.20628863 0.24054511]\n",
      "Epoch 7: loss = 0.17, Ypred = [0.60361209 0.18453738 0.21185053]\n",
      "Epoch 8: loss = 0.13, Ypred = [0.67061183 0.15450303 0.17488514]\n",
      "Epoch 9: loss = 0.099, Ypred = [0.74284715 0.12246583 0.13468702]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([0.1, 0.2, 0.7])\n",
    "Y = np.array([1.0, 0.0, 0.0])\n",
    "W = np.array([[[0.1, 0.2, 0.3],\n",
    "             [0.3, 0.2, 0.7],\n",
    "             [0.1, 0.2, 0.3]],\n",
    "            [[0.2, 0.3, 0.5],\n",
    "             [0.3, 0.5, 0.7],\n",
    "             [0.6, 0.4, 0.8]],\n",
    "            [[0.1, 0.4, 0.8],\n",
    "             [0.3, 0.7, 0.2],\n",
    "             [0.5, 0.2, 0.9]]])\n",
    "\n",
    "epoch = 100\n",
    "\n",
    "for i in range(epoch):\n",
    "    Z1 = W[0] @ X\n",
    "    H1 = RELU(Z1)\n",
    "    \n",
    "    Z2 = W[1] @ H1\n",
    "    H2 = Sigmoid(Z2)\n",
    "    \n",
    "    Z3 = W[2] @ H2\n",
    "    H3 = Softmax(Z3)\n",
    "    Ypred = H3\n",
    "    \n",
    "    loss = CrossEntropy(Ypred, Y)\n",
    "    print(\"Epoch {}: loss = {:.2}, Ypred = {}\".format(i, loss, Ypred))\n",
    "    if loss < 0.1:\n",
    "        break\n",
    "    \n",
    "    dw = np.zeros_like(W)\n",
    "    learning_rate = 0.1\n",
    "\n",
    "    dLoss = dCrossEntropy(Ypred, Y)\n",
    "    \n",
    "    dLoss = dLoss * dSoftmax(Z3)\n",
    "    dw[2] = dLoss * H2\n",
    "    dLoss = dLoss * W[2] * dSigmoid(Z2)\n",
    "    dw[1] = dLoss * H1\n",
    "    dLoss = dLoss * W[1] * dRELU(H1)\n",
    "    dw[0] = dLoss * X\n",
    "    W -= learning_rate * dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#0328fc\">С помощью стандартных пакетов</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Generate dummy data\n",
    "import keras\n",
    "x_train = np.random.random((1000, 20))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)\n",
    "x_test = np.random.random((100, 20))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#9d03fc\">1. sklearn</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "X_scaler = StandardScaler()\n",
    "X_scaled = X_scaler.fit_transform(x_train)\n",
    "y_scaler = StandardScaler() \n",
    "y_scaled = y_scaler.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "inp_size = X_scaled.shape[1]\n",
    "L1_size = 64\n",
    "L2_size = 64\n",
    "out_size = 10\n",
    "print(f\"neurons: IN=<{inp_size}>, L1=<{L1_size}>, L2=<{L2_size}>, OUT=<{out_size}>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "X_scaled.shape, y_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# количество входных переменных\n",
    "\n",
    "\n",
    "\n",
    "mlp = MLPRegressor(solver='adam',\n",
    "                   alpha=1e-4,\n",
    "                   activation='relu',\n",
    "                   learning_rate_init = 0.01,\n",
    "                   max_iter=100,\n",
    "                   hidden_layer_sizes=(L1_size, L2_size, out_size),\n",
    "                   shuffle=True,\n",
    "                   random_state=12)\n",
    "\n",
    "print(X_scaled.shape,y_scaled.shape)\n",
    "\n",
    "mlp =  mlp.fit(X_scaled, y_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test_y = y_scaler.inverse_transform( mlp.predict(X_scaler.transform(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#9d03fc\">2. keras</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "#\n",
    "from keras.layers import Dense, Activation,Dropout\n",
    "from keras.models import Sequential\n",
    "#\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# https://gist.github.com/candlewill/552fa102352ccce42fd829ae26277d24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Dense(64) is a fully-connected layer with 64 hidden units.\n",
    "# in the first layer, you must specify the expected input data shape:\n",
    "# here, 20-dimensional vectors.\n",
    "model.add(Dense(L1_size, activation='relu', input_dim=20))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(L2_size, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(out_size, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=15, batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#9d03fc\">3. Pytorch</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Ваш код\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back propagation\n",
    "\n",
    "https://towardsdatascience.com/understanding-backpropagation-algorithm-7bb3aa2f95fd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проблемы MLP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/tikz36.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __много параметров__\n",
    "$$\n",
    "N = N_{вх} * N_{hidden 1} +  N_{hidden 1} * N_{hidden 2} + ...  N_{hidden N-1}* N_{hidden N} + N_{hidden N} * N_{вых}\n",
    "$$<br>\n",
    "Следствия:\n",
    "    - медленно\n",
    "    - легко переобучается\n",
    "<br><br>\n",
    "* __затухающие градиенты__\n",
    "    - градиент прогонятеся обратно\n",
    "    - много слоев - может остаться маленькая часть или даже обнулиться\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Способы решения\n",
    "* нормализация (normalization / batch normalizaiton)\n",
    "* \"отсеивание\" (dropout)\n",
    "* \"черезслойные\" связи (residual networks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}